{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f56a7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jojotitichaya/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jojotitichaya/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jojotitichaya/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imageio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.34.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imageio) (1.26.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imageio) (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: moviepy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (10.1.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opencv-python) (1.26.0)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (2.34.2)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai \n",
    "%pip install python-dotenv\n",
    "%pip install torch torchvision\n",
    "%pip install pandas numpy matplotlib \n",
    "%pip install imageio\n",
    "%pip install certifi\n",
    "%pip install opencv-python moviepy pillow\n",
    "%pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdf4803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import imageio\n",
    "\n",
    "from openai import OpenAI \n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "import base64\n",
    "import json\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57330e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77948b8a",
   "metadata": {},
   "source": [
    "# Process input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29f1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in taichi/taichi_1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted 8 frames\n",
      "Extracted audio to taichi/taichi_1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "VIDEO_PATH = \"taichi/taichi_1.mp4\"\n",
    "\n",
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame = 0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    # Extract audio from video if audio track is present\n",
    "    audio_path = None\n",
    "    clip = VideoFileClip(video_path)\n",
    "    if clip.audio is not None:\n",
    "        audio_path = f\"{base_video_path}.mp3\"\n",
    "        clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
    "        clip.audio.close()\n",
    "\n",
    "    clip.close()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    if audio_path:\n",
    "        print(f\"Extracted audio to {audio_path}\")\n",
    "    else:\n",
    "        print(\"No audio track found in the video\")\n",
    "\n",
    "    return base64Frames, audio_path\n",
    "\n",
    "# Extract 1 frame per second. You can adjust the `seconds_per_frame` parameter to change the sampling rate\n",
    "base64Frames, audio_path = process_video(VIDEO_PATH, seconds_per_frame=1)\n",
    "\n",
    "transcription_text = \"\"\n",
    "if audio_path:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=open(audio_path, \"rb\"),\n",
    "    )\n",
    "    transcription_text = transcription.text\n",
    "else:\n",
    "    transcription_text = \"No audio track available to transcribe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596d2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaiChi\n"
     ]
    }
   ],
   "source": [
    "## Categorize the video\n",
    "categorization_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are a classifier. Classify the provided video into one of the following categories: Vox (talking head), TEDTalk (standing talking), TaiChi, MGIF Respond with only category (one word).\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            \"These are the frames from the video.\",\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
    "            {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription_text}\"}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Extract the classification result and store it in a variable\n",
    "category = categorization_response.choices[0].message.content.strip()\n",
    "\n",
    "# Print categorization response\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a69aa",
   "metadata": {},
   "source": [
    "# Refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba64fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to customize the prompt based on video category\n",
    "def generate_prompt(category):\n",
    "    if category == \"Vox\":\n",
    "        return \"Refine facial features and enhance clarity in expressions.\"\n",
    "    elif category == \"TEDTalk\":\n",
    "        return \"Enhance detail and clarity in full body standing posture.\"\n",
    "    elif category == \"TaiChi\":\n",
    "        return \"Increase smoothness and continuity in movement.\"\n",
    "    elif category == \"MGIF\":\n",
    "        return \"Apply creative enhancements to make the scene more vivid.\"\n",
    "    else:\n",
    "        return \"Enhance general image quality.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b257b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-B4qda9PQ7BkBhFr5EoAEAP2r.png?st=2024-07-18T13%3A54%3A31Z&se=2024-07-18T15%3A54%3A31Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T09%3A35%3A02Z&ske=2024-07-19T09%3A35%3A02Z&sks=b&skv=2023-11-03&sig=I3omAx3NoMqLbLXsWENA4ggF7%2B73k2YxSKZPRuSN8aQ%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-BSPPYH9LERlpIlutvniulEPe.png?st=2024-07-18T13%3A54%3A43Z&se=2024-07-18T15%3A54%3A43Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T00%3A29%3A08Z&ske=2024-07-19T00%3A29%3A08Z&sks=b&skv=2023-11-03&sig=4YCD%2B%2BxP7NGi/5kGnVX7s6x%2BYSM65w1QHtrmsdoCjIA%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-18ppQX3TFHFZQFm4Z83GNi9K.png?st=2024-07-18T13%3A54%3A55Z&se=2024-07-18T15%3A54%3A55Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T14%3A00%3A41Z&ske=2024-07-19T14%3A00%3A41Z&sks=b&skv=2023-11-03&sig=TH%2BFLdcEM%2B09qXjU9nDy2FyqS8AdJKILX8zqGBQfZ00%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-77DvIJ43d9isOgMjfUbYFmvT.png?st=2024-07-18T13%3A55%3A07Z&se=2024-07-18T15%3A55%3A07Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T00%3A36%3A52Z&ske=2024-07-19T00%3A36%3A52Z&sks=b&skv=2023-11-03&sig=yjkTwNpwcZDNJ/LfEYPiZ%2BV4dsmxV5oN5Lgb3y4MQFw%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-9NuLgexILIIJ8y7kj1nKtOiI.png?st=2024-07-18T13%3A55%3A20Z&se=2024-07-18T15%3A55%3A20Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A43%3A13Z&ske=2024-07-19T13%3A43%3A13Z&sks=b&skv=2023-11-03&sig=2xKAfyQoz5jEf0oPBt8EypjnxAyyb2EAA3/uWFrV9DE%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-LSXop9pG7N5SoP1zW7oXvScy.png?st=2024-07-18T13%3A55%3A32Z&se=2024-07-18T15%3A55%3A32Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T14%3A12%3A16Z&ske=2024-07-19T14%3A12%3A16Z&sks=b&skv=2023-11-03&sig=QUq8Rbm2AT%2B6lrVH0BWVYPyeH4gq8SRYmQ%2Bkr0qe5Fc%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-oR6Hxc2E4RcEifATTEL8KurZ.png?st=2024-07-18T13%3A55%3A44Z&se=2024-07-18T15%3A55%3A44Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T12%3A43%3A54Z&ske=2024-07-19T12%3A43%3A54Z&sks=b&skv=2023-11-03&sig=ix5WOO0rYua4lMveMu3y7xsr/OXYEXTWAgGkZE7Jlso%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-XOOqDAs2xjkPJuLPJSa7VPBU.png?st=2024-07-18T13%3A55%3A56Z&se=2024-07-18T15%3A55%3A56Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T14%3A08%3A44Z&ske=2024-07-19T14%3A08%3A44Z&sks=b&skv=2023-11-03&sig=nc1KtctNQvkwDrYUGiXsCl8/gb5R/pEnZD7WHnx/FEs%3D']\n"
     ]
    }
   ],
   "source": [
    "# Function to convert base64 string to binary\n",
    "def base64_to_image(base64_string):\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    return BytesIO(img_data)  # This converts the binary data to a bytes buffer\n",
    "\n",
    "# List to hold URLs of refined images\n",
    "refined_image_urls = []\n",
    "\n",
    "# Process each base64 encoded frame\n",
    "for base64_string in base64Frames:\n",
    "    image_binary = base64_to_image(base64_string)\n",
    "    prompt = generate_prompt(category)\n",
    "    \n",
    "    # Call DALL-E 2 to create a variation of the frame\n",
    "    response = client.images.create_variation(\n",
    "        model=\"dall-e-2\",\n",
    "        image=image_binary,\n",
    "        n=1,\n",
    "        size=\"1024x1024\",\n",
    "        prompt=prompt\n",
    "    )\n",
    "    \n",
    "    # Extract the URL of the refined image and store it\n",
    "    image_url = response.data[0].url\n",
    "    refined_image_urls.append(image_url)\n",
    "\n",
    "# Print URLs or do something with the refined images\n",
    "print(refined_image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "132f1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = [\".\", \"/\"]\n",
    "string = VIDEO_PATH\n",
    "for delimiter in delimiters:\n",
    "    string = \" \".join(string.split(delimiter))\n",
    "\n",
    "video_name = string.split()[1]\n",
    "video_name\n",
    "\n",
    "# Ensure the specific video results folder exists\n",
    "video_results_path = f'results/{video_name}'\n",
    "if not os.path.exists(video_results_path):\n",
    "    os.makedirs(video_results_path)\n",
    "\n",
    "# Function to save images\n",
    "def save_images(urls, base_path):\n",
    "    for i, url in enumerate(urls):\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(os.path.join(base_path, f'image_{i}.png'))  # Saves images as image_0.png, image_1.png, etc.\n",
    "\n",
    "# Call save_images with the URL list and the specific path for this video\n",
    "save_images(refined_image_urls, video_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d23a8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base64Frames, category, video_name):\n",
    "    base_path = f'{category}/{video_name}'\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    for i, base64_string in enumerate(base64Frames):\n",
    "        image_binary = BytesIO(base64.b64decode(base64_string))\n",
    "        img = Image.open(image_binary)\n",
    "        img.save(os.path.join(base_path, f'img_{i}.png'))\n",
    "\n",
    "\n",
    "seconds_per_frame = 1\n",
    "save_images(base64Frames, category.lower(), video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7403fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to results/taichi_1/output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "def create_video_from_images(folder_path, output_video_file, fps=30):\n",
    "    # Get all image files from the folder\n",
    "    images = [img for img in natsorted(os.listdir(folder_path)) if img.endswith(\".png\")]\n",
    "    if not images:\n",
    "        print(\"No images found in the directory.\")\n",
    "        return\n",
    "\n",
    "    frame = cv2.imread(os.path.join(folder_path, images[0]))\n",
    "    if frame is None:\n",
    "        print(\"Error loading the first image.\")\n",
    "        return\n",
    "\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'XVID' can be used for AVI files\n",
    "    video = cv2.VideoWriter(output_video_file, fourcc, fps, (width, height))\n",
    "\n",
    "    for image in images:\n",
    "        img = cv2.imread(os.path.join(folder_path, image))\n",
    "        if img is not None:\n",
    "            video.write(img)\n",
    "        else:\n",
    "            print(f\"Error loading image {image}\")\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video saved to {output_video_file}\")\n",
    "\n",
    "folder_path = f'results/{video_name}'  # Corrected folder path where images are stored\n",
    "output_video_file = f'results/{video_name}/output_video.mp4'  # Corrected output video file path\n",
    "\n",
    "create_video_from_images(folder_path, output_video_file, fps=10)  # fps can be adjusted based on original video or preference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
