{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f56a7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.18.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jojotitichaya/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jojotitichaya/Library/Python/3.11/lib/python/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jojotitichaya/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imageio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.34.2)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imageio) (1.26.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imageio) (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: moviepy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (10.1.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opencv-python) (1.26.0)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (2.34.2)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai \n",
    "%pip install python-dotenv\n",
    "%pip install torch torchvision\n",
    "%pip install pandas numpy matplotlib \n",
    "%pip install imageio\n",
    "%pip install certifi\n",
    "%pip install opencv-python moviepy pillow\n",
    "%pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bdf4803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import imageio\n",
    "\n",
    "from openai import OpenAI \n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "import base64\n",
    "import json\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c57330e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77948b8a",
   "metadata": {},
   "source": [
    "# Process input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d29f1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in tedtalk/ted_1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted 11 frames\n",
      "Extracted audio to tedtalk/ted_1.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "VIDEO_PATH = \"tedtalk/ted_1.mp4\"\n",
    "\n",
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame = 0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    # Extract audio from video if audio track is present\n",
    "    audio_path = None\n",
    "    clip = VideoFileClip(video_path)\n",
    "    if clip.audio is not None:\n",
    "        audio_path = f\"{base_video_path}.mp3\"\n",
    "        clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
    "        clip.audio.close()\n",
    "\n",
    "    clip.close()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    if audio_path:\n",
    "        print(f\"Extracted audio to {audio_path}\")\n",
    "    else:\n",
    "        print(\"No audio track found in the video\")\n",
    "\n",
    "    return base64Frames, audio_path\n",
    "\n",
    "# Extract 1 frame per second. You can adjust the `seconds_per_frame` parameter to change the sampling rate\n",
    "base64Frames, audio_path = process_video(VIDEO_PATH, seconds_per_frame=1)\n",
    "\n",
    "transcription_text = \"\"\n",
    "if audio_path:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=open(audio_path, \"rb\"),\n",
    "    )\n",
    "    transcription_text = transcription.text\n",
    "else:\n",
    "    transcription_text = \"No audio track available to transcribe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "596d2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEDTalk\n"
     ]
    }
   ],
   "source": [
    "## Categorize the video\n",
    "categorization_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are a classifier. Classify the provided video into one of the following categories: Vox (talking head), TEDTalk (standing talking), TaiChi, MGIF Respond with only category (one word).\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            \"These are the frames from the video.\",\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
    "            {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription_text}\"}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Extract the classification result and store it in a variable\n",
    "category = categorization_response.choices[0].message.content.strip()\n",
    "\n",
    "# Print categorization response\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a69aa",
   "metadata": {},
   "source": [
    "# Refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7512794b",
   "metadata": {},
   "source": [
    "create prompt for each catagory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba64fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to customize the prompt based on video category\n",
    "# def generate_prompt(category):\n",
    "#     if category == \"Vox\":\n",
    "#         return \"Enhance this image by refining facial features and increasing the clarity of expressions. Focus on improving skin texture, facial contours, and the brightness of the eyes to make the subject more engaging and visually appealing, while preserving the natural look and emotional expression of the person.\"\n",
    "#     elif category == \"TEDTalk\":\n",
    "#         return \"Improve the visual quality of this image by enhancing the detail and clarity of the speaker’s full body posture. Enhance the sharpness of the clothing and make the background slightly blurred to keep the focus on the speaker. Ensure that the speaker’s posture and gestures are clearly visible and appear more dynamic and pronounced without altering their natural stance.\"\n",
    "#     elif category == \"TaiChi\":\n",
    "#         return \"Enhance this image of a Tai Chi practitioner by improving the visual clarity and detail of the clothing and background, while preserving the exact posture and alignment of the practitioner. Increase the smoothness and continuity in the appearance of the movement, ensuring that the limbs maintain their original positions and the flow of the Tai Chi form is clear. The goal is to make the image sharper and more vivid, highlighting the grace and precision of the Tai Chi movements without changing the stance or altering the sequence of the movement.\"\n",
    "#     elif category == \"MGIF\":\n",
    "#         return \"Enhance this animated scene by applying creative and vivid enhancements to make it more engaging. Increase the saturation and contrast to make the colors pop. Add subtle motion blur to emphasize movement and bring a dynamic feel to the scene, while ensuring that key visual elements remain clear and easily distinguishable.\"\n",
    "#     else:\n",
    "#         return \"Enhance general image quality.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452c0fc",
   "metadata": {},
   "source": [
    "generate refine image for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b257b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-MBw6hhI9pUy9T4m5xeNGWYT0.png?st=2024-07-18T15%3A55%3A40Z&se=2024-07-18T17%3A55%3A40Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T14%3A10%3A46Z&ske=2024-07-19T14%3A10%3A46Z&sks=b&skv=2023-11-03&sig=8QD02FtI7%2BNBLZGQfTPtfo92jSwywRyt8vau27clRrA%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-SbErptkP11ErKvM13hqpgoad.png?st=2024-07-18T15%3A55%3A52Z&se=2024-07-18T17%3A55%3A52Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A33%3A22Z&ske=2024-07-19T13%3A33%3A22Z&sks=b&skv=2023-11-03&sig=vhwIOOqABT8mFd2tUti0vXdrVWpi%2BNSGJPll28/T9Ec%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-1htvVUSV59AEOvgdweFMXMjo.png?st=2024-07-18T15%3A56%3A05Z&se=2024-07-18T17%3A56%3A05Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-17T22%3A53%3A53Z&ske=2024-07-18T22%3A53%3A53Z&sks=b&skv=2023-11-03&sig=8zIRx8RJpoy83Z6ZL1UGIu8HWyzqMV3OG4VaM2RE/l4%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-hHKkPEr2I05FXGfzprymvoaZ.png?st=2024-07-18T15%3A56%3A18Z&se=2024-07-18T17%3A56%3A18Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A45%3A48Z&ske=2024-07-19T13%3A45%3A48Z&sks=b&skv=2023-11-03&sig=zZx8HNnN0t9Zi0cDV7Ah7kvxVO%2B2S2seW13WB8N1ZMY%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-fH1sv4A0hFUnNiSExGFjWtfg.png?st=2024-07-18T15%3A56%3A31Z&se=2024-07-18T17%3A56%3A31Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T09%3A19%3A49Z&ske=2024-07-19T09%3A19%3A49Z&sks=b&skv=2023-11-03&sig=IIPCdeRm7IUud8MLq%2B94%2BdsmRpISguX0ALQL0g9rxaM%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-uOxVHUr0nR9dL2FzXdCYvNnq.png?st=2024-07-18T15%3A56%3A43Z&se=2024-07-18T17%3A56%3A43Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A29%3A06Z&ske=2024-07-19T13%3A29%3A06Z&sks=b&skv=2023-11-03&sig=Ww65QiU6VOL4b9%2Bl/0t0NhugVoOi57g6jZdneAyTOno%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-oeu1QSpgUnjWEkbqNx43HAHV.png?st=2024-07-18T15%3A56%3A55Z&se=2024-07-18T17%3A56%3A55Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A22%3A43Z&ske=2024-07-19T13%3A22%3A43Z&sks=b&skv=2023-11-03&sig=n9e1Y7kQPXIy5uOfG7jGOPUpd66vBrqDmoAmaD5GHAM%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-U80Ljo8pVmX6XOtTvRAmM3zx.png?st=2024-07-18T15%3A57%3A08Z&se=2024-07-18T17%3A57%3A08Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A09%3A01Z&ske=2024-07-19T13%3A09%3A01Z&sks=b&skv=2023-11-03&sig=nxqJkW1PKPkeYRPLmUI4VVq0XwvrSE/vvX6pfSeuWJ4%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-umQQuWZGneHhQxC1eosOaOv3.png?st=2024-07-18T15%3A57%3A21Z&se=2024-07-18T17%3A57%3A21Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T12%3A09%3A17Z&ske=2024-07-19T12%3A09%3A17Z&sks=b&skv=2023-11-03&sig=HI2h3G1zOO8ItdlJxHGNtQZR120vU%2B172SYU3dVjBBE%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-wENTQqIAIz2gWZCUUEF8fzKP.png?st=2024-07-18T15%3A57%3A35Z&se=2024-07-18T17%3A57%3A35Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T13%3A57%3A56Z&ske=2024-07-19T13%3A57%3A56Z&sks=b&skv=2023-11-03&sig=cnkTjnWEUtJse46aG7nK2ToLaWyO0UD8dbliwu9m0m8%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-MpDZgoa1LpMCkeCfptyN7cBz.png?st=2024-07-18T15%3A57%3A50Z&se=2024-07-18T17%3A57%3A50Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-18T00%3A31%3A48Z&ske=2024-07-19T00%3A31%3A48Z&sks=b&skv=2023-11-03&sig=%2BBvhXnt2ilL37E0C0tG72qUcBvTSMJ8jjMpGPZ7NPxE%3D']\n"
     ]
    }
   ],
   "source": [
    "def base64_to_image(base64_string):\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(BytesIO(img_data))\n",
    "\n",
    "    # Convert image to 'RGBA' format\n",
    "    if img.mode != 'RGBA':\n",
    "        img = img.convert('RGBA')\n",
    "\n",
    "    img_buffer = BytesIO()\n",
    "    img.save(img_buffer, format=\"PNG\")\n",
    "    img_buffer.seek(0)  # Reset buffer position to the beginning\n",
    "    return img_buffer\n",
    "\n",
    "# List to hold URLs of refined images\n",
    "refined_image_urls = []\n",
    "\n",
    "# Process each base64 encoded frame\n",
    "for base64_string in base64Frames:\n",
    "    image_binary = base64_to_image(base64_string)\n",
    "    image_binary.seek(0)  # Reset buffer position to the beginning after writing\n",
    "\n",
    "    # Ensure the image is under the size limit (4MB)\n",
    "    if image_binary.getbuffer().nbytes > 4000000:\n",
    "        print(\"Image exceeds the 4MB size limit.\")\n",
    "        continue\n",
    "\n",
    "    # Call DALL-E 2 to edit the frame\n",
    "    response = client.images.create_variation(\n",
    "        model=\"dall-e-2\",\n",
    "        image=image_binary,\n",
    "        n=1,\n",
    "        size=\"1024x1024\",\n",
    "    )\n",
    "    \n",
    "    # Extract the URL of the refined image and store it\n",
    "    image_url = response.data[0].url\n",
    "    refined_image_urls.append(image_url)\n",
    "\n",
    "# Print URLs or do something with the refined images\n",
    "print(refined_image_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee4e38",
   "metadata": {},
   "source": [
    "# Save images\n",
    "output frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "132f1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get video resolution\n",
    "def get_video_resolution(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video.release()\n",
    "    return width, height\n",
    "\n",
    "def save_images(urls, base_path, target_width, target_height):\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    \n",
    "    for i, url in enumerate(urls):\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        # Use the LANCZOS resampling filter for high-quality downsampling\n",
    "        img = img.resize((target_width, target_height), Image.LANCZOS)  # Directly using Image.LANCZOS\n",
    "        img.save(os.path.join(base_path, f'image_{i}.png'))  # Saves images as image_0.png, image_1.png, etc.\n",
    "        \n",
    "# Usage example with paths and video resolution function as previously defined\n",
    "video_name = VIDEO_PATH.split('/')[1].split('.')[0]  # Extract video name from path\n",
    "video_results_path = f'results/{video_name}'\n",
    "original_width, original_height = get_video_resolution(VIDEO_PATH)\n",
    "\n",
    "# Ensure the specific video results folder exists\n",
    "if not os.path.exists(video_results_path):\n",
    "    os.makedirs(video_results_path)\n",
    "\n",
    "# Final call to save_images with the URL list and the specific path for this video\n",
    "save_images(refined_image_urls, video_results_path, original_width, original_height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47529f3b",
   "metadata": {},
   "source": [
    "input frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d23a8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base64Frames, category, video_name):\n",
    "    base_path = f'{category}/{video_name}'\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    for i, base64_string in enumerate(base64Frames):\n",
    "        image_binary = BytesIO(base64.b64decode(base64_string))\n",
    "        img = Image.open(image_binary)\n",
    "        img.save(os.path.join(base_path, f'img_{i}.png'))\n",
    "\n",
    "\n",
    "seconds_per_frame = 1\n",
    "save_images(base64Frames, category.lower(), video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2cc1662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collage saved to results/ted_1/collage.png\n",
      "Collage saved to tedtalk/ted_1/collage.png\n"
     ]
    }
   ],
   "source": [
    "def create_horizontal_collage(image_paths, output_path, frame_count=7):\n",
    "    # Open all images and ensure they are the same height\n",
    "    images = [Image.open(image_path) for image_path in image_paths[:frame_count]]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    \n",
    "    # Calculate the total width and maximum height of the collage\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    # Create a new image with the total width and max height\n",
    "    collage_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    # Paste each image into the collage image\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        collage_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "\n",
    "    # Save the collage image\n",
    "    collage_image.save(output_path)\n",
    "    print(f\"Collage saved to {output_path}\")\n",
    "\n",
    "\n",
    "# output\n",
    "frame_indices = list(range(len(base64Frames)))\n",
    "image_paths = [f\"results/{video_name}/image_{index}.png\" for index in frame_indices]\n",
    "output_path = f\"results/{video_name}/collage.png\"\n",
    "create_horizontal_collage(image_paths, output_path)\n",
    "\n",
    "\n",
    "# input\n",
    "image_paths = [f\"{category.lower()}/{video_name}/img_{index}.png\" for index in frame_indices]\n",
    "output_path = f\"{category.lower()}/{video_name}/collage.png\"\n",
    "create_horizontal_collage(image_paths, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
