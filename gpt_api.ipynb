{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9f56a7a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install -q openai \n",
    "# %pip install python-dotenv\n",
    "# %pip install torch torchvision\n",
    "# %pip install pandas numpy matplotlib \n",
    "# %pip install imageio\n",
    "# %pip install certifi\n",
    "# %pip install opencv-python moviepy pillow\n",
    "# %pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bdf4803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import imageio\n",
    "\n",
    "from openai import OpenAI \n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "import base64\n",
    "import json\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c57330e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "MODEL = \"gpt-4o\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77948b8a",
   "metadata": {},
   "source": [
    "# Process input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "d29f1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in vox/mp4/id08911/5B2DdFJ6P60/00011.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Extracted 8 frames\n",
      "Extracted audio to vox/mp4/id08911/5B2DdFJ6P60/00011.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "VIDEO_PATH = \"vox/mp4/id08911/5B2DdFJ6P60/00011.mp4\"\n",
    "\n",
    "def process_video(video_path, seconds_per_frame=2):\n",
    "    base64Frames = []\n",
    "    base_video_path, _ = os.path.splitext(video_path)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frames_to_skip = int(fps * seconds_per_frame)\n",
    "    curr_frame = 0\n",
    "\n",
    "    # Loop through the video and extract frames at specified sampling rate\n",
    "    while curr_frame < total_frames - 1:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, curr_frame)\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "        base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "        curr_frame += frames_to_skip\n",
    "    video.release()\n",
    "\n",
    "    # Extract audio from video if audio track is present\n",
    "    audio_path = None\n",
    "    clip = VideoFileClip(video_path)\n",
    "    if clip.audio is not None:\n",
    "        audio_path = f\"{base_video_path}.mp3\"\n",
    "        clip.audio.write_audiofile(audio_path, bitrate=\"32k\")\n",
    "        clip.audio.close()\n",
    "\n",
    "    clip.close()\n",
    "\n",
    "    print(f\"Extracted {len(base64Frames)} frames\")\n",
    "    if audio_path:\n",
    "        print(f\"Extracted audio to {audio_path}\")\n",
    "    else:\n",
    "        print(\"No audio track found in the video\")\n",
    "\n",
    "    return base64Frames, audio_path\n",
    "\n",
    "# Extract 1 frame per second. You can adjust the `seconds_per_frame` parameter to change the sampling rate\n",
    "base64Frames, audio_path = process_video(VIDEO_PATH, seconds_per_frame=1)\n",
    "\n",
    "transcription_text = \"\"\n",
    "if audio_path:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=open(audio_path, \"rb\"),\n",
    "    )\n",
    "    transcription_text = transcription.text\n",
    "else:\n",
    "    transcription_text = \"No audio track available to transcribe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "596d2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vox\n"
     ]
    }
   ],
   "source": [
    "## Categorize the video\n",
    "categorization_response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are a classifier. Classify the provided video into one of the following categories: Vox (talking head), TEDTalk (standing talking), TaiChi, MGIF Respond with only category (one word).\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            \"These are the frames from the video.\",\n",
    "            *map(lambda x: {\"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f'data:image/jpg;base64,{x}', \"detail\": \"low\"}}, base64Frames),\n",
    "            {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription_text}\"}\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Extract the classification result and store it in a variable\n",
    "category = categorization_response.choices[0].message.content.strip()\n",
    "\n",
    "# Print categorization response\n",
    "print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a69aa",
   "metadata": {},
   "source": [
    "# Refinements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452c0fc",
   "metadata": {},
   "source": [
    "generate refine image for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "b257b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-c74AZFrwVSbCmCGZhNul1CW1.png?st=2024-08-08T14%3A00%3A37Z&se=2024-08-08T16%3A00%3A37Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T06%3A48%3A36Z&ske=2024-08-09T06%3A48%3A36Z&sks=b&skv=2023-11-03&sig=RN%2BF2MRWBBT5uM%2B7inw63m4j9R2Zzb2b5F5n9rWuRO0%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-ohqoaJACdlQ9ebULLShVPnwo.png?st=2024-08-08T14%3A00%3A46Z&se=2024-08-08T16%3A00%3A46Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T06%3A57%3A36Z&ske=2024-08-09T06%3A57%3A36Z&sks=b&skv=2023-11-03&sig=eLm5GdLlMqLfMgvEl/4QBtRefS/7lz3aJpCMzreykl8%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-WpHSdXzakLr2x5P3POSMftiE.png?st=2024-08-08T14%3A00%3A55Z&se=2024-08-08T16%3A00%3A55Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T06%3A53%3A38Z&ske=2024-08-09T06%3A53%3A38Z&sks=b&skv=2023-11-03&sig=vnERz7jZbZsjbjeCJcFUEJByZL%2BckSOx1Nl2pPmraHA%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-U0DQke7L8len8MmEQQRJew87.png?st=2024-08-08T14%3A01%3A05Z&se=2024-08-08T16%3A01%3A05Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T04%3A16%3A41Z&ske=2024-08-09T04%3A16%3A41Z&sks=b&skv=2023-11-03&sig=v6mlV%2B5kumG%2ByvbgWrm76iW5BvxgpNml5ayvWsqi254%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-EC8iSBh4Wzb8WhN0gAOKfoDX.png?st=2024-08-08T14%3A01%3A17Z&se=2024-08-08T16%3A01%3A17Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-07T19%3A59%3A33Z&ske=2024-08-08T19%3A59%3A33Z&sks=b&skv=2023-11-03&sig=PSK16dqxZD4Ew3FOE6yuLQLvP8DwOtZdtQWiR5FxUdI%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-1ulC6y2HmVN1hEB38ZLzqEUu.png?st=2024-08-08T14%3A01%3A30Z&se=2024-08-08T16%3A01%3A30Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T04%3A56%3A46Z&ske=2024-08-09T04%3A56%3A46Z&sks=b&skv=2023-11-03&sig=6FYsI3gtaW8GhDZxeatHJQvJJavU80I%2BP4EnLQInaUc%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-2aeDzUE6NV9y025NAq13iFBm.png?st=2024-08-08T14%3A01%3A41Z&se=2024-08-08T16%3A01%3A41Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T05%3A02%3A25Z&ske=2024-08-09T05%3A02%3A25Z&sks=b&skv=2023-11-03&sig=UAZBq3owVMC/JSZZMQ099l/bS15%2B90dsBDHAD8gsp2M%3D', 'https://oaidalleapiprodscus.blob.core.windows.net/private/org-kJ4senBWYHe37wdtKBeAwzbB/user-9njMec9uaOq5EPKA2k4J0TEd/img-Qwj3bG01CvbHbI3E0Ts9gl7X.png?st=2024-08-08T14%3A01%3A50Z&se=2024-08-08T16%3A01%3A50Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-08T06%3A10%3A21Z&ske=2024-08-09T06%3A10%3A21Z&sks=b&skv=2023-11-03&sig=uesT1c%2BbTa/mc6hVjknCcaKfbYVW7U1pM%2BO99yov9Es%3D']\n"
     ]
    }
   ],
   "source": [
    "def base64_to_image(base64_string):\n",
    "    img_data = base64.b64decode(base64_string)\n",
    "    img = Image.open(BytesIO(img_data))\n",
    "\n",
    "    # Convert image to 'RGBA' format\n",
    "    if img.mode != 'RGBA':\n",
    "        img = img.convert('RGBA')\n",
    "\n",
    "    img_buffer = BytesIO()\n",
    "    img.save(img_buffer, format=\"PNG\")\n",
    "    img_buffer.seek(0)  # Reset buffer position to the beginning\n",
    "    return img_buffer\n",
    "\n",
    "# List to hold URLs of refined images\n",
    "refined_image_urls = []\n",
    "\n",
    "# Process each base64 encoded frame\n",
    "for base64_string in base64Frames:\n",
    "    image_binary = base64_to_image(base64_string)\n",
    "    image_binary.seek(0)  # Reset buffer position to the beginning after writing\n",
    "\n",
    "    # Ensure the image is under the size limit (4MB)\n",
    "    if image_binary.getbuffer().nbytes > 4000000:\n",
    "        print(\"Image exceeds the 4MB size limit.\")\n",
    "        continue\n",
    "\n",
    "    # Call DALL-E 2 to edit the frame\n",
    "    response = client.images.create_variation(\n",
    "        model=\"dall-e-2\",\n",
    "        image=image_binary,\n",
    "        n=1,\n",
    "        size=\"1024x1024\",\n",
    "    )\n",
    "    \n",
    "    # Extract the URL of the refined image and store it\n",
    "    image_url = response.data[0].url\n",
    "    refined_image_urls.append(image_url)\n",
    "\n",
    "# Print URLs or do something with the refined images\n",
    "print(refined_image_urls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee4e38",
   "metadata": {},
   "source": [
    "# Save images\n",
    "output frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "132f1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get video resolution\n",
    "def get_video_resolution(video_path):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video.release()\n",
    "    return width, height\n",
    "\n",
    "def save_images(urls, base_path, target_width, target_height):\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    \n",
    "    for i, url in enumerate(urls):\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        # Use the LANCZOS resampling filter for high-quality downsampling\n",
    "        img = img.resize((target_width, target_height), Image.LANCZOS)  # Directly using Image.LANCZOS\n",
    "        img.save(os.path.join(base_path, f'image_{i}.png'))  # Saves images as image_0.png, image_1.png, etc.\n",
    "        \n",
    "# Usage example with paths and video resolution function as previously defined\n",
    "video_name = VIDEO_PATH.split('/')[1].split('.')[0]  # Extract video name from path\n",
    "video_results_path = f'results/{video_name}'\n",
    "original_width, original_height = get_video_resolution(VIDEO_PATH)\n",
    "\n",
    "# Ensure the specific video results folder exists\n",
    "if not os.path.exists(video_results_path):\n",
    "    os.makedirs(video_results_path)\n",
    "\n",
    "# Final call to save_images with the URL list and the specific path for this video\n",
    "save_images(refined_image_urls, video_results_path, original_width, original_height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47529f3b",
   "metadata": {},
   "source": [
    "input frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d23a8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base64Frames, category, video_name):\n",
    "    base_path = f'{category}/{video_name}'\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "\n",
    "    for i, base64_string in enumerate(base64Frames):\n",
    "        image_binary = BytesIO(base64.b64decode(base64_string))\n",
    "        img = Image.open(image_binary)\n",
    "        img.save(os.path.join(base_path, f'img_{i}.png'))\n",
    "\n",
    "\n",
    "seconds_per_frame = 1\n",
    "save_images(base64Frames, category.lower(), video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2cc1662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collage saved to results/mp4/collage.png\n",
      "Collage saved to vox/mp4/collage.png\n"
     ]
    }
   ],
   "source": [
    "def create_horizontal_collage(image_paths, output_path, frame_count=7):\n",
    "    # Open all images and ensure they are the same height\n",
    "    images = [Image.open(image_path) for image_path in image_paths[:frame_count]]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    \n",
    "    # Calculate the total width and maximum height of the collage\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "\n",
    "    # Create a new image with the total width and max height\n",
    "    collage_image = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "    # Paste each image into the collage image\n",
    "    x_offset = 0\n",
    "    for img in images:\n",
    "        collage_image.paste(img, (x_offset, 0))\n",
    "        x_offset += img.width\n",
    "\n",
    "    # Save the collage image\n",
    "    collage_image.save(output_path)\n",
    "    print(f\"Collage saved to {output_path}\")\n",
    "\n",
    "\n",
    "# output\n",
    "frame_indices = list(range(len(base64Frames)))\n",
    "image_paths = [f\"results/{video_name}/image_{index}.png\" for index in frame_indices]\n",
    "output_path = f\"results/{video_name}/collage.png\"\n",
    "create_horizontal_collage(image_paths, output_path)\n",
    "\n",
    "\n",
    "# input\n",
    "image_paths = [f\"{category.lower()}/{video_name}/img_{index}.png\" for index in frame_indices]\n",
    "output_path = f\"{category.lower()}/{video_name}/collage.png\"\n",
    "create_horizontal_collage(image_paths, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
